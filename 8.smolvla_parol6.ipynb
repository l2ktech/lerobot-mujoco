{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7082c8b7",
   "metadata": {},
   "source": [
    "# Deploy Trained Smolvla Policy\n",
    "\n",
    "<img src=\"./media/rollout3.gif\" width=\"480\" height=\"360\">\n",
    "\n",
    "Deploy trained policy in simulation.\n",
    "# ========================================\n",
    "# 8.smolvla.ipynb - SmolVLAç­–ç•¥éƒ¨ç½²ä¸æµ‹è¯•\n",
    "# ========================================\n",
    "# åŠŸèƒ½ï¼šåŠ è½½è®­ç»ƒå¥½çš„SmolVLAæ¨¡å‹ï¼Œå¹¶åœ¨MuJoCoä»¿çœŸç¯å¢ƒä¸­è¿›è¡Œå®é™…éƒ¨ç½²æµ‹è¯•\n",
    "# SmolVLA = Small Vision-Language-Action Modelï¼ˆå°å‹è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - è®¾ç½®ç¯å¢ƒå˜é‡(å¿…é¡»ç¬¬ä¸€ä¸ªè¿è¡Œ)\n",
    "import os\n",
    "\n",
    "# 1. è®¾ç½®DISPLAY\n",
    "os.environ['DISPLAY'] = ':0'\n",
    "os.environ['XAUTHORITY'] = os.path.expanduser('~/.Xauthority')\n",
    "print(f\"âœ“ DISPLAYè®¾ç½®ä¸º: {os.environ['DISPLAY']}\")\n",
    "\n",
    "# 2. å¼ºåˆ¶ä½¿ç”¨GPUæ¸²æŸ“(å…³é”®!)\n",
    "os.environ['MUJOCO_GL'] = 'egl'  # EGLåç«¯GPUåŠ é€Ÿ\n",
    "print(f\"âœ“ MUJOCO_GL: egl (GPUç¡¬ä»¶åŠ é€Ÿ)\")\n",
    "\n",
    "# 3. NVIDIA GPUä¼˜åŒ–\n",
    "os.environ['__GL_SYNC_TO_VBLANK'] = '0'  # å…³é—­å‚ç›´åŒæ­¥\n",
    "os.environ['__GL_YIELD'] = 'NOTHING'      # å‡å°‘CPUç­‰å¾…\n",
    "print(\"âœ“ NVIDIA GPUä¼˜åŒ–å·²å¯ç”¨\")\n",
    "\n",
    "# 4. OpenGLæ€§èƒ½ä¼˜åŒ–\n",
    "os.environ['__GL_FSAA_MODE'] = '0'        # å…³é—­æŠ—é”¯é½¿\n",
    "os.environ['__GL_LOG_MAX_ANISO'] = '0'    # å…³é—­å„å‘å¼‚æ€§è¿‡æ»¤\n",
    "print(\"âœ“ OpenGLæ€§èƒ½ä¼˜åŒ–å·²å¯ç”¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.50.3\n",
    "!pip install num2words\n",
    "!pip install accelerate\n",
    "!pip install safetensors>=0.4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c036d1f",
   "metadata": {},
   "source": [
    "### [Optional] Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c3d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If you want to use the collected dataset, please download it from Hugging Face.\n",
    "'''\n",
    "#!git clone https://huggingface.co/datasets/Jeongeun/omy_pnp_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07033fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli download Jeongeun/omy_pnp_language --repo-type dataset --local-dir ./demo_data_language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a246fa3e",
   "metadata": {},
   "source": [
    "## Step 2. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python train_model.py --config_path smolvla_omy.yaml\n",
    "from train_with_monitor_cell import train_with_monitor\n",
    "train_with_monitor(\"smolvla_omy.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20673462",
   "metadata": {},
   "source": [
    "## Step 3. Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07386e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wzy/envs/lerobot-mujoco/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
    "import numpy as np\n",
    "from lerobot.common.datasets.utils import write_json, serialize_dict\n",
    "from lerobot.common.policies.smolvla.configuration_smolvla import SmolVLAConfig\n",
    "from lerobot.common.policies.smolvla.modeling_smolvla import SmolVLAPolicy\n",
    "from lerobot.configs.types import FeatureType\n",
    "from lerobot.common.datasets.factory import resolve_delta_timestamps\n",
    "from lerobot.common.datasets.utils import dataset_to_policy_features\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b1f651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381de80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dataset_metadata = LeRobotDatasetMetadata(\"omy_pnp_language\", root='./demo_data_language')\n",
    "except:\n",
    "    dataset_metadata = LeRobotDatasetMetadata(\"omy_pnp_language\", root='./omy_pnp_language')\n",
    "features = dataset_to_policy_features(dataset_metadata.features)\n",
    "output_features = {key: ft for key, ft in features.items() if ft.type is FeatureType.ACTION}\n",
    "input_features = {key: ft for key, ft in features.items() if key not in output_features}\n",
    "# Policies are initialized with a configuration class, in this case `DiffusionConfig`. For this example,\n",
    "# we'll just use the defaults and so no arguments other than input/output features need to be passed.\n",
    "# Temporal ensemble to make smoother trajectory predictions\n",
    "cfg = SmolVLAConfig(input_features=input_features, output_features=output_features, chunk_size= 5, n_action_steps=5)\n",
    "delta_timestamps = resolve_delta_timestamps(cfg, dataset_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e38030a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing the number of VLM layers to 16 ...\n",
      "Loading weights from local directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SmolVLAPolicy(\n",
       "  (normalize_inputs): Normalize(\n",
       "    (buffer_observation_state): ParameterDict(\n",
       "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 6 (cuda:0)]\n",
       "        (std): Parameter containing: [torch.cuda.FloatTensor of size 6 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (normalize_targets): Normalize(\n",
       "    (buffer_action): ParameterDict(\n",
       "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "        (std): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (unnormalize_outputs): Unnormalize(\n",
       "    (buffer_action): ParameterDict(\n",
       "        (mean): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "        (std): Parameter containing: [torch.cuda.FloatTensor of size 7 (cuda:0)]\n",
       "    )\n",
       "  )\n",
       "  (model): VLAFlowMatching(\n",
       "    (vlm_with_expert): SmolVLMWithExpertModel(\n",
       "      (vlm): SmolVLMForConditionalGeneration(\n",
       "        (model): SmolVLMModel(\n",
       "          (vision_model): SmolVLMVisionTransformer(\n",
       "            (embeddings): SmolVLMVisionEmbeddings(\n",
       "              (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), padding=valid)\n",
       "              (position_embedding): Embedding(1024, 768)\n",
       "            )\n",
       "            (encoder): SmolVLMEncoder(\n",
       "              (layers): ModuleList(\n",
       "                (0-11): 12 x SmolVLMEncoderLayer(\n",
       "                  (self_attn): SmolVLMVisionAttention(\n",
       "                    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  )\n",
       "                  (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "                  (mlp): SmolVLMVisionMLP(\n",
       "                    (activation_fn): PytorchGELUTanh()\n",
       "                    (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  )\n",
       "                  (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (post_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (connector): SmolVLMConnector(\n",
       "            (modality_projection): SmolVLMSimpleMLP(\n",
       "              (proj): Linear(in_features=12288, out_features=960, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (text_model): LlamaModel(\n",
       "            (embed_tokens): Embedding(49280, 960, padding_idx=2)\n",
       "            (layers): ModuleList(\n",
       "              (0-15): 16 x LlamaDecoderLayer(\n",
       "                (self_attn): LlamaAttention(\n",
       "                  (q_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "                  (k_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "                  (v_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "                  (o_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "                )\n",
       "                (mlp): LlamaMLP(\n",
       "                  (gate_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "                  (up_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "                  (down_proj): Linear(in_features=2560, out_features=960, bias=False)\n",
       "                  (act_fn): SiLU()\n",
       "                )\n",
       "                (input_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "                (post_attention_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "              )\n",
       "            )\n",
       "            (norm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "        )\n",
       "        (lm_head): Linear(in_features=960, out_features=49280, bias=False)\n",
       "      )\n",
       "      (lm_expert): LlamaModel(\n",
       "        (embed_tokens): None\n",
       "        (layers): ModuleList(\n",
       "          (0): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (1): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (2): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (3): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (4): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (5): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (6): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (7): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (8): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (9): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (10): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (11): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (12): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (13): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (14): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=720, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "          (15): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(in_features=720, out_features=960, bias=False)\n",
       "              (k_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (v_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (o_proj): Linear(in_features=960, out_features=720, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (up_proj): Linear(in_features=720, out_features=2048, bias=False)\n",
       "              (down_proj): Linear(in_features=2048, out_features=720, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((720,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "    )\n",
       "    (state_proj): Linear(in_features=32, out_features=960, bias=True)\n",
       "    (action_in_proj): Linear(in_features=32, out_features=720, bias=True)\n",
       "    (action_out_proj): Linear(in_features=720, out_features=32, bias=True)\n",
       "    (action_time_mlp_in): Linear(in_features=1440, out_features=720, bias=True)\n",
       "    (action_time_mlp_out): Linear(in_features=720, out_features=720, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now instantiate our policy with this config and the dataset stats.\n",
    "policy = SmolVLAPolicy.from_pretrained('ckpt/smolvla_omy4060_20251103_224510/checkpoints/last/pretrained_model', dataset_stats=dataset_metadata.stats)\n",
    "# You can load the trained policy from hub if you don't have the resources to train it.\n",
    "# policy = SmolVLAPolicy.from_pretrained(\"Jeongeun/omy_pnp_pi0\", config=cfg, dataset_stats=dataset_metadata.stats)\n",
    "policy.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e83f1f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ DISPLAYè®¾ç½®ä¸º: :0\n",
      "âœ“ MUJOCO_GL: egl (GPUç¡¬ä»¶åŠ é€Ÿ)\n",
      "âœ“ NVIDIA GPUä¼˜åŒ–å·²å¯ç”¨\n",
      "âœ“ OpenGLæ€§èƒ½ä¼˜åŒ–å·²å¯ç”¨\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 - è®¾ç½®ç¯å¢ƒå˜é‡(å¿…é¡»ç¬¬ä¸€ä¸ªè¿è¡Œ)\n",
    "import os\n",
    "\n",
    "# 1. è®¾ç½®DISPLAY\n",
    "os.environ['DISPLAY'] = ':0'\n",
    "os.environ['XAUTHORITY'] = os.path.expanduser('~/.Xauthority')\n",
    "print(f\"âœ“ DISPLAYè®¾ç½®ä¸º: {os.environ['DISPLAY']}\")\n",
    "\n",
    "# 2. å¼ºåˆ¶ä½¿ç”¨GPUæ¸²æŸ“(å…³é”®!)\n",
    "os.environ['MUJOCO_GL'] = 'egl'  # EGLåç«¯GPUåŠ é€Ÿ\n",
    "print(f\"âœ“ MUJOCO_GL: egl (GPUç¡¬ä»¶åŠ é€Ÿ)\")\n",
    "\n",
    "# 3. NVIDIA GPUä¼˜åŒ–\n",
    "os.environ['__GL_SYNC_TO_VBLANK'] = '0'  # å…³é—­å‚ç›´åŒæ­¥\n",
    "os.environ['__GL_YIELD'] = 'NOTHING'      # å‡å°‘CPUç­‰å¾…\n",
    "print(\"âœ“ NVIDIA GPUä¼˜åŒ–å·²å¯ç”¨\")\n",
    "\n",
    "# 4. OpenGLæ€§èƒ½ä¼˜åŒ–\n",
    "os.environ['__GL_FSAA_MODE'] = '0'        # å…³é—­æŠ—é”¯é½¿\n",
    "os.environ['__GL_LOG_MAX_ANISO'] = '0'    # å…³é—­å„å‘å¼‚æ€§è¿‡æ»¤\n",
    "print(\"âœ“ OpenGLæ€§èƒ½ä¼˜åŒ–å·²å¯ç”¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85ebd9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------\n",
      "name:[Tabletop] dt:[0.002] HZ:[500]\n",
      " n_qpos:[31] n_qvel:[28] n_qacc:[28] n_ctrl:[10]\n",
      " integrator:[IMPLICITFAST]\n",
      "\n",
      "n_body:[23]\n",
      " [0/23] [world] mass:[0.00]kg\n",
      " [1/23] [front_object_table] mass:[1.00]kg\n",
      " [2/23] [camera] mass:[0.00]kg\n",
      " [3/23] [camera2] mass:[0.00]kg\n",
      " [4/23] [camera3] mass:[0.00]kg\n",
      " [5/23] [link1] mass:[2.06]kg\n",
      " [6/23] [link2] mass:[3.68]kg\n",
      " [7/23] [link3] mass:[2.39]kg\n",
      " [8/23] [link4] mass:[1.40]kg\n",
      " [9/23] [link5] mass:[1.40]kg\n",
      " [10/23] [link6] mass:[0.65]kg\n",
      " [11/23] [camera_center] mass:[0.00]kg\n",
      " [12/23] [tcp_link] mass:[0.32]kg\n",
      " [13/23] [rh_p12_rn_r1] mass:[0.07]kg\n",
      " [14/23] [rh_p12_rn_r2] mass:[0.02]kg\n",
      " [15/23] [rh_p12_rn_l1] mass:[0.07]kg\n",
      " [16/23] [rh_p12_rn_l2] mass:[0.02]kg\n",
      " [17/23] [body_obj_mug_5] mass:[0.00]kg\n",
      " [18/23] [object_mug_5] mass:[0.08]kg\n",
      " [19/23] [body_obj_plate_11] mass:[0.00]kg\n",
      " [20/23] [object_plate_11] mass:[0.10]kg\n",
      " [21/23] [body_obj_mug_6] mass:[0.00]kg\n",
      " [22/23] [object_mug_6] mass:[0.08]kg\n",
      "body_total_mass:[13.35]kg\n",
      "\n",
      "n_geom:[116]\n",
      "geom_names:['floor', None, 'front_object_table', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "\n",
      "n_mesh:[112]\n",
      "mesh_names:['base_unit', 'link1', 'link2', 'link3', 'link4', 'link5', 'link6', 'flange', 'base', 'r1', 'r2', 'l1', 'l2', 'mug_5_normalized_0_vis', 'mug_5_normalized_collision_22._coll', 'mug_5_normalized_collision_23._coll', 'mug_5_normalized_collision_21._coll', 'mug_5_normalized_collision_20._coll', 'mug_5_normalized_collision_24._coll', 'mug_5_normalized_collision_30._coll', 'mug_5_normalized_collision_18._coll', 'mug_5_normalized_collision_19._coll', 'mug_5_normalized_collision_31._coll', 'mug_5_normalized_collision_25._coll', 'mug_5_normalized_collision_27._coll', 'mug_5_normalized_collision_26._coll', 'mug_5_normalized_collision_9._coll', 'mug_5_normalized_collision_8._coll', 'mug_5_normalized_collision_6._coll', 'mug_5_normalized_collision_7._coll', 'mug_5_normalized_collision_5._coll', 'mug_5_normalized_collision_4._coll', 'mug_5_normalized_collision_0._coll', 'mug_5_normalized_collision_1._coll', 'mug_5_normalized_collision_3._coll', 'mug_5_normalized_collision_2._coll', 'mug_5_normalized_collision_17._coll', 'mug_5_normalized_collision_16._coll', 'mug_5_normalized_collision_28._coll', 'mug_5_normalized_collision_14._coll', 'mug_5_normalized_collision_15._coll', 'mug_5_normalized_collision_29._coll', 'mug_5_normalized_collision_11._coll', 'mug_5_normalized_collision_10._coll', 'mug_5_normalized_collision_12._coll', 'mug_5_normalized_collision_13._coll', 'plate_11_normalized_0_vis', 'plate_11_normalized_collision_22._coll', 'plate_11_normalized_collision_23._coll', 'plate_11_normalized_collision_21._coll', 'plate_11_normalized_collision_20._coll', 'plate_11_normalized_collision_24._coll', 'plate_11_normalized_collision_30._coll', 'plate_11_normalized_collision_18._coll', 'plate_11_normalized_collision_19._coll', 'plate_11_normalized_collision_31._coll', 'plate_11_normalized_collision_25._coll', 'plate_11_normalized_collision_27._coll', 'plate_11_normalized_collision_26._coll', 'plate_11_normalized_collision_9._coll', 'plate_11_normalized_collision_8._coll', 'plate_11_normalized_collision_6._coll', 'plate_11_normalized_collision_7._coll', 'plate_11_normalized_collision_5._coll', 'plate_11_normalized_collision_4._coll', 'plate_11_normalized_collision_0._coll', 'plate_11_normalized_collision_1._coll', 'plate_11_normalized_collision_3._coll', 'plate_11_normalized_collision_2._coll', 'plate_11_normalized_collision_17._coll', 'plate_11_normalized_collision_16._coll', 'plate_11_normalized_collision_28._coll', 'plate_11_normalized_collision_14._coll', 'plate_11_normalized_collision_15._coll', 'plate_11_normalized_collision_29._coll', 'plate_11_normalized_collision_11._coll', 'plate_11_normalized_collision_10._coll', 'plate_11_normalized_collision_12._coll', 'plate_11_normalized_collision_13._coll', 'mug_6_normalized_0_vis', 'mug_6_normalized_collision_22._coll', 'mug_6_normalized_collision_23._coll', 'mug_6_normalized_collision_21._coll', 'mug_6_normalized_collision_20._coll', 'mug_6_normalized_collision_24._coll', 'mug_6_normalized_collision_30._coll', 'mug_6_normalized_collision_18._coll', 'mug_6_normalized_collision_19._coll', 'mug_6_normalized_collision_31._coll', 'mug_6_normalized_collision_25._coll', 'mug_6_normalized_collision_27._coll', 'mug_6_normalized_collision_26._coll', 'mug_6_normalized_collision_9._coll', 'mug_6_normalized_collision_8._coll', 'mug_6_normalized_collision_6._coll', 'mug_6_normalized_collision_7._coll', 'mug_6_normalized_collision_5._coll', 'mug_6_normalized_collision_4._coll', 'mug_6_normalized_collision_0._coll', 'mug_6_normalized_collision_1._coll', 'mug_6_normalized_collision_3._coll', 'mug_6_normalized_collision_2._coll', 'mug_6_normalized_collision_17._coll', 'mug_6_normalized_collision_16._coll', 'mug_6_normalized_collision_28._coll', 'mug_6_normalized_collision_14._coll', 'mug_6_normalized_collision_15._coll', 'mug_6_normalized_collision_29._coll', 'mug_6_normalized_collision_11._coll', 'mug_6_normalized_collision_10._coll', 'mug_6_normalized_collision_12._coll', 'mug_6_normalized_collision_13._coll']\n",
      "\n",
      "n_joint:[13]\n",
      " [0/13] [joint1] axis:[0. 0. 1.]\n",
      " [1/13] [joint2] axis:[0. 1. 0.]\n",
      " [2/13] [joint3] axis:[0. 1. 0.]\n",
      " [3/13] [joint4] axis:[0. 1. 0.]\n",
      " [4/13] [joint5] axis:[0. 0. 1.]\n",
      " [5/13] [joint6] axis:[0. 1. 0.]\n",
      " [6/13] [rh_r1] axis:[1. 0. 0.]\n",
      " [7/13] [rh_r2] axis:[-1.  0.  0.]\n",
      " [8/13] [rh_l1] axis:[-1.  0.  0.]\n",
      " [9/13] [rh_l2] axis:[1. 0. 0.]\n",
      " [10/13] [None] axis:[0. 0. 1.]\n",
      " [11/13] [None] axis:[0. 0. 1.]\n",
      " [12/13] [None] axis:[0. 0. 1.]\n",
      "\n",
      "n_dof:[28] (=number of rows of Jacobian)\n",
      " [0/28] [None] attached joint:[joint1] body:[link1]\n",
      " [1/28] [None] attached joint:[joint2] body:[link2]\n",
      " [2/28] [None] attached joint:[joint3] body:[link3]\n",
      " [3/28] [None] attached joint:[joint4] body:[link4]\n",
      " [4/28] [None] attached joint:[joint5] body:[link5]\n",
      " [5/28] [None] attached joint:[joint6] body:[link6]\n",
      " [6/28] [None] attached joint:[rh_r1] body:[rh_p12_rn_r1]\n",
      " [7/28] [None] attached joint:[rh_r2] body:[rh_p12_rn_r2]\n",
      " [8/28] [None] attached joint:[rh_l1] body:[rh_p12_rn_l1]\n",
      " [9/28] [None] attached joint:[rh_l2] body:[rh_p12_rn_l2]\n",
      " [10/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [11/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [12/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [13/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [14/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [15/28] [None] attached joint:[None] body:[body_obj_mug_5]\n",
      " [16/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [17/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [18/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [19/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [20/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [21/28] [None] attached joint:[None] body:[body_obj_plate_11]\n",
      " [22/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [23/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [24/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [25/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [26/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      " [27/28] [None] attached joint:[None] body:[body_obj_mug_6]\n",
      "\n",
      "Free joint information. n_free_joint:[3]\n",
      " [0/3] [None] body_name_attached:[body_obj_mug_5]\n",
      " [1/3] [None] body_name_attached:[body_obj_plate_11]\n",
      " [2/3] [None] body_name_attached:[body_obj_mug_6]\n",
      "\n",
      "Revolute joint information. n_rev_joint:[10]\n",
      " [0/10] [joint1] range:[-6.283]~[6.283]\n",
      " [1/10] [joint2] range:[-6.283]~[6.283]\n",
      " [2/10] [joint3] range:[-6.283]~[6.283]\n",
      " [3/10] [joint4] range:[-6.283]~[6.283]\n",
      " [4/10] [joint5] range:[-6.283]~[6.283]\n",
      " [5/10] [joint6] range:[-6.283]~[6.283]\n",
      " [6/10] [rh_r1] range:[0.000]~[1.100]\n",
      " [7/10] [rh_r2] range:[0.000]~[1.000]\n",
      " [8/10] [rh_l1] range:[0.000]~[1.100]\n",
      " [9/10] [rh_l2] range:[0.000]~[1.000]\n",
      "\n",
      "Prismatic joint information. n_pri_joint:[0]\n",
      "\n",
      "Control information. n_ctrl:[10]\n",
      " [0/10] [actuator_joint1] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [1/10] [actuator_joint2] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [2/10] [actuator_joint3] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [3/10] [actuator_joint4] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [4/10] [actuator_joint5] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [5/10] [actuator_joint6] range:[-6.283]~[6.283] gear:[1.00] type:[JOINT]\n",
      " [6/10] [actuator_rh_r1] range:[0.000]~[1.100] gear:[1.00] type:[JOINT]\n",
      " [7/10] [actuator_rh_r2] range:[0.000]~[1.000] gear:[1.00] type:[JOINT]\n",
      " [8/10] [actuator_rh_l1] range:[0.000]~[1.100] gear:[1.00] type:[JOINT]\n",
      " [9/10] [actuator_rh_l2] range:[0.000]~[1.000] gear:[1.00] type:[JOINT]\n",
      "\n",
      "Camera information. n_cam:[4]\n",
      " [0/4] [agentview] fov:[60.0]\n",
      " [1/4] [topview] fov:[90.0]\n",
      " [2/4] [sideview] fov:[90.0]\n",
      " [3/4] [egocentric] fov:[90.0]\n",
      "\n",
      "n_sensor:[0]\n",
      "sensor_names:[]\n",
      "n_site:[9]\n",
      "site_names:['bottom_site_mug_5', 'top_site_mug_5', 'horizontal_radius_site_mug_5', 'bottom_site_plate_11', 'top_site_plate_11', 'horizontal_radius_site_plate_11', 'bottom_site_mug_6', 'top_site_mug_6', 'horizontal_radius_site_mug_6']\n",
      "-----------------------------------------------------------------------------\n",
      "env:[Tabletop] reset\n",
      "env:[Tabletop] reset\n",
      "env:[Tabletop] initalize viewer\n",
      "DONE INITIALIZATION\n"
     ]
    }
   ],
   "source": [
    "from mujoco_env.y_env2 import SimpleEnv2\n",
    "xml_path = './asset/example_scene_y2.xml'\n",
    "PnPEnv = SimpleEnv2(xml_path, action_type='joint_angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db761f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "# Approach 1: Using torchvision.transforms\n",
    "def get_default_transform(image_size: int = 224):\n",
    "    \"\"\"\n",
    "    Returns a torchvision transform that:\n",
    "     Converts to a FloatTensor and scales pixel values [0,255] -> [0.0,1.0]\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),  # PIL [0â€“255] -> FloatTensor [0.0â€“1.0], shape CÃ—HÃ—W\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f070ae79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸš€ STARTING POLICY EVALUATION | å¼€å§‹ç­–ç•¥è¯„ä¼°\n",
      "================================================================================\n",
      "Start Time | å¼€å§‹æ—¶é—´: 2025-11-04 12:00:03\n",
      "Total Episodes | æ€»å›åˆæ•°: 100\n",
      "Timeout | è¶…æ—¶æ—¶é—´: 30s\n",
      "Control Frequency | æ§åˆ¶é¢‘ç‡: 20Hz\n",
      "================================================================================\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 1/100 started... | å›åˆ 1/100 å¼€å§‹... âœ… SUCCESS in 8.98s (95 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 2/100 started... | å›åˆ 2/100 å¼€å§‹... âœ… SUCCESS in 9.97s (101 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 3/100 started... | å›åˆ 3/100 å¼€å§‹... âœ… SUCCESS in 15.38s (160 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 4/100 started... | å›åˆ 4/100 å¼€å§‹... âœ… SUCCESS in 15.54s (156 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 5/100 started... | å›åˆ 5/100 å¼€å§‹... âœ… SUCCESS in 9.28s (95 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 6/100 started... | å›åˆ 6/100 å¼€å§‹... âœ… SUCCESS in 15.07s (152 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 7/100 started... | å›åˆ 7/100 å¼€å§‹... âœ… SUCCESS in 10.03s (101 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 8/100 started... | å›åˆ 8/100 å¼€å§‹... âœ… SUCCESS in 14.52s (150 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 9/100 started... | å›åˆ 9/100 å¼€å§‹... âœ… SUCCESS in 14.98s (151 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 10/100 started... | å›åˆ 10/100 å¼€å§‹... âœ… SUCCESS in 14.86s (154 steps) | æˆåŠŸ\n",
      "\n",
      "ğŸ“Š Progress: 10/100 | Success Rate: 100.00% | æˆåŠŸç‡: 100.00%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 11/100 started... | å›åˆ 11/100 å¼€å§‹... âœ… SUCCESS in 10.12s (105 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 12/100 started... | å›åˆ 12/100 å¼€å§‹... âœ… SUCCESS in 15.23s (156 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 13/100 started... | å›åˆ 13/100 å¼€å§‹... âœ… SUCCESS in 10.07s (101 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 14/100 started... | å›åˆ 14/100 å¼€å§‹... âœ… SUCCESS in 14.70s (152 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 15/100 started... | å›åˆ 15/100 å¼€å§‹... âœ… SUCCESS in 14.92s (152 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 16/100 started... | å›åˆ 16/100 å¼€å§‹... âœ… SUCCESS in 15.24s (156 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 17/100 started... | å›åˆ 17/100 å¼€å§‹... âœ… SUCCESS in 9.71s (99 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 18/100 started... | å›åˆ 18/100 å¼€å§‹... âœ… SUCCESS in 9.34s (96 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 19/100 started... | å›åˆ 19/100 å¼€å§‹... âœ… SUCCESS in 14.82s (151 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 20/100 started... | å›åˆ 20/100 å¼€å§‹... âœ… SUCCESS in 15.41s (157 steps) | æˆåŠŸ\n",
      "\n",
      "ğŸ“Š Progress: 20/100 | Success Rate: 100.00% | æˆåŠŸç‡: 100.00%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 21/100 started... | å›åˆ 21/100 å¼€å§‹... âœ… SUCCESS in 15.06s (154 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 22/100 started... | å›åˆ 22/100 å¼€å§‹... âœ… SUCCESS in 13.87s (141 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 23/100 started... | å›åˆ 23/100 å¼€å§‹... âœ… SUCCESS in 9.61s (99 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 24/100 started... | å›åˆ 24/100 å¼€å§‹... âœ… SUCCESS in 9.56s (98 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 25/100 started... | å›åˆ 25/100 å¼€å§‹... âœ… SUCCESS in 9.37s (98 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 26/100 started... | å›åˆ 26/100 å¼€å§‹... âœ… SUCCESS in 15.76s (161 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 27/100 started... | å›åˆ 27/100 å¼€å§‹... â±ï¸  TIMEOUT after 30.3s | è¶…æ—¶\n",
      "DONE INITIALIZATION\n",
      "Episode 28/100 started... | å›åˆ 28/100 å¼€å§‹... âœ… SUCCESS in 14.53s (152 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 29/100 started... | å›åˆ 29/100 å¼€å§‹... âœ… SUCCESS in 10.18s (102 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 30/100 started... | å›åˆ 30/100 å¼€å§‹... âœ… SUCCESS in 14.77s (151 steps) | æˆåŠŸ\n",
      "\n",
      "ğŸ“Š Progress: 30/100 | Success Rate: 96.67% | æˆåŠŸç‡: 96.67%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 31/100 started... | å›åˆ 31/100 å¼€å§‹... âœ… SUCCESS in 14.43s (147 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 32/100 started... | å›åˆ 32/100 å¼€å§‹... âœ… SUCCESS in 14.77s (154 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 33/100 started... | å›åˆ 33/100 å¼€å§‹... âœ… SUCCESS in 9.80s (102 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 34/100 started... | å›åˆ 34/100 å¼€å§‹... âœ… SUCCESS in 10.04s (103 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 35/100 started... | å›åˆ 35/100 å¼€å§‹... âœ… SUCCESS in 14.35s (147 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 36/100 started... | å›åˆ 36/100 å¼€å§‹... âœ… SUCCESS in 15.54s (160 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 37/100 started... | å›åˆ 37/100 å¼€å§‹... âœ… SUCCESS in 10.17s (103 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 38/100 started... | å›åˆ 38/100 å¼€å§‹... âœ… SUCCESS in 9.97s (101 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 39/100 started... | å›åˆ 39/100 å¼€å§‹... âœ… SUCCESS in 9.61s (100 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 40/100 started... | å›åˆ 40/100 å¼€å§‹... âœ… SUCCESS in 10.94s (111 steps) | æˆåŠŸ\n",
      "\n",
      "ğŸ“Š Progress: 40/100 | Success Rate: 97.50% | æˆåŠŸç‡: 97.50%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 41/100 started... | å›åˆ 41/100 å¼€å§‹... âœ… SUCCESS in 14.22s (145 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 42/100 started... | å›åˆ 42/100 å¼€å§‹... âœ… SUCCESS in 9.90s (101 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 43/100 started... | å›åˆ 43/100 å¼€å§‹... âœ… SUCCESS in 15.24s (156 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 44/100 started... | å›åˆ 44/100 å¼€å§‹... âœ… SUCCESS in 10.02s (103 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 45/100 started... | å›åˆ 45/100 å¼€å§‹... âœ… SUCCESS in 14.74s (151 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 46/100 started... | å›åˆ 46/100 å¼€å§‹... âœ… SUCCESS in 17.94s (186 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 47/100 started... | å›åˆ 47/100 å¼€å§‹... âœ… SUCCESS in 11.41s (116 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 48/100 started... | å›åˆ 48/100 å¼€å§‹... âœ… SUCCESS in 14.92s (151 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 49/100 started... | å›åˆ 49/100 å¼€å§‹... âœ… SUCCESS in 9.82s (101 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 50/100 started... | å›åˆ 50/100 å¼€å§‹... âœ… SUCCESS in 9.96s (104 steps) | æˆåŠŸ\n",
      "\n",
      "ğŸ“Š Progress: 50/100 | Success Rate: 98.00% | æˆåŠŸç‡: 98.00%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 51/100 started... | å›åˆ 51/100 å¼€å§‹... âœ… SUCCESS in 13.04s (131 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 52/100 started... | å›åˆ 52/100 å¼€å§‹... âœ… SUCCESS in 10.47s (106 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 53/100 started... | å›åˆ 53/100 å¼€å§‹... âœ… SUCCESS in 10.08s (103 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 54/100 started... | å›åˆ 54/100 å¼€å§‹... âœ… SUCCESS in 14.86s (151 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 55/100 started... | å›åˆ 55/100 å¼€å§‹... âœ… SUCCESS in 9.19s (94 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 56/100 started... | å›åˆ 56/100 å¼€å§‹... âœ… SUCCESS in 15.42s (160 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 57/100 started... | å›åˆ 57/100 å¼€å§‹... âœ… SUCCESS in 9.78s (100 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 58/100 started... | å›åˆ 58/100 å¼€å§‹... âœ… SUCCESS in 15.64s (161 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 59/100 started... | å›åˆ 59/100 å¼€å§‹... âœ… SUCCESS in 14.51s (148 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 60/100 started... | å›åˆ 60/100 å¼€å§‹... â±ï¸  TIMEOUT after 30.2s | è¶…æ—¶\n",
      "\n",
      "ğŸ“Š Progress: 60/100 | Success Rate: 96.67% | æˆåŠŸç‡: 96.67%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 61/100 started... | å›åˆ 61/100 å¼€å§‹... âœ… SUCCESS in 9.98s (101 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 62/100 started... | å›åˆ 62/100 å¼€å§‹... âœ… SUCCESS in 15.37s (156 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 63/100 started... | å›åˆ 63/100 å¼€å§‹... âœ… SUCCESS in 10.11s (104 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 64/100 started... | å›åˆ 64/100 å¼€å§‹... âœ… SUCCESS in 15.24s (156 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 65/100 started... | å›åˆ 65/100 å¼€å§‹... âœ… SUCCESS in 15.08s (153 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 66/100 started... | å›åˆ 66/100 å¼€å§‹... âœ… SUCCESS in 11.13s (115 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 67/100 started... | å›åˆ 67/100 å¼€å§‹... âœ… SUCCESS in 10.63s (107 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 68/100 started... | å›åˆ 68/100 å¼€å§‹... âœ… SUCCESS in 15.12s (155 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 69/100 started... | å›åˆ 69/100 å¼€å§‹... âœ… SUCCESS in 9.97s (102 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 70/100 started... | å›åˆ 70/100 å¼€å§‹... âœ… SUCCESS in 10.84s (111 steps) | æˆåŠŸ\n",
      "\n",
      "ğŸ“Š Progress: 70/100 | Success Rate: 97.14% | æˆåŠŸç‡: 97.14%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 71/100 started... | å›åˆ 71/100 å¼€å§‹... âœ… SUCCESS in 14.44s (152 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 72/100 started... | å›åˆ 72/100 å¼€å§‹... âœ… SUCCESS in 13.93s (147 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 73/100 started... | å›åˆ 73/100 å¼€å§‹... âœ… SUCCESS in 14.68s (154 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 74/100 started... | å›åˆ 74/100 å¼€å§‹... âœ… SUCCESS in 9.71s (101 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 75/100 started... | å›åˆ 75/100 å¼€å§‹... âœ… SUCCESS in 9.92s (101 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 76/100 started... | å›åˆ 76/100 å¼€å§‹... âœ… SUCCESS in 9.81s (101 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 77/100 started... | å›åˆ 77/100 å¼€å§‹... âœ… SUCCESS in 9.93s (103 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 78/100 started... | å›åˆ 78/100 å¼€å§‹... âœ… SUCCESS in 9.57s (98 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 79/100 started... | å›åˆ 79/100 å¼€å§‹... âœ… SUCCESS in 9.48s (96 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 80/100 started... | å›åˆ 80/100 å¼€å§‹... âœ… SUCCESS in 9.52s (99 steps) | æˆåŠŸ\n",
      "\n",
      "ğŸ“Š Progress: 80/100 | Success Rate: 97.50% | æˆåŠŸç‡: 97.50%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 81/100 started... | å›åˆ 81/100 å¼€å§‹... âœ… SUCCESS in 18.73s (195 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 82/100 started... | å›åˆ 82/100 å¼€å§‹... âœ… SUCCESS in 13.22s (136 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 83/100 started... | å›åˆ 83/100 å¼€å§‹... âœ… SUCCESS in 12.89s (131 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 84/100 started... | å›åˆ 84/100 å¼€å§‹... âœ… SUCCESS in 14.92s (155 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 85/100 started... | å›åˆ 85/100 å¼€å§‹... âœ… SUCCESS in 10.16s (101 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 86/100 started... | å›åˆ 86/100 å¼€å§‹... âœ… SUCCESS in 11.91s (121 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 87/100 started... | å›åˆ 87/100 å¼€å§‹... âœ… SUCCESS in 10.02s (101 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 88/100 started... | å›åˆ 88/100 å¼€å§‹... âœ… SUCCESS in 9.72s (100 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 89/100 started... | å›åˆ 89/100 å¼€å§‹... âœ… SUCCESS in 14.80s (151 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 90/100 started... | å›åˆ 90/100 å¼€å§‹... âœ… SUCCESS in 15.42s (160 steps) | æˆåŠŸ\n",
      "\n",
      "ğŸ“Š Progress: 90/100 | Success Rate: 97.78% | æˆåŠŸç‡: 97.78%\n",
      "\n",
      "DONE INITIALIZATION\n",
      "Episode 91/100 started... | å›åˆ 91/100 å¼€å§‹... âœ… SUCCESS in 14.76s (152 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 92/100 started... | å›åˆ 92/100 å¼€å§‹... âœ… SUCCESS in 11.94s (121 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 93/100 started... | å›åˆ 93/100 å¼€å§‹... âœ… SUCCESS in 15.11s (153 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 94/100 started... | å›åˆ 94/100 å¼€å§‹... âœ… SUCCESS in 15.21s (156 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 95/100 started... | å›åˆ 95/100 å¼€å§‹... âœ… SUCCESS in 15.41s (156 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 96/100 started... | å›åˆ 96/100 å¼€å§‹... âœ… SUCCESS in 14.76s (151 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 97/100 started... | å›åˆ 97/100 å¼€å§‹... âœ… SUCCESS in 14.51s (151 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 98/100 started... | å›åˆ 98/100 å¼€å§‹... âœ… SUCCESS in 14.82s (151 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 99/100 started... | å›åˆ 99/100 å¼€å§‹... âœ… SUCCESS in 14.20s (146 steps) | æˆåŠŸ\n",
      "DONE INITIALIZATION\n",
      "Episode 100/100 started... | å›åˆ 100/100 å¼€å§‹... âœ… SUCCESS in 14.96s (155 steps) | æˆåŠŸ\n",
      "\n",
      "ğŸ“Š Progress: 100/100 | Success Rate: 98.00% | æˆåŠŸç‡: 98.00%\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ EVALUATION COMPLETED | è¯„ä¼°å®Œæˆ\n",
      "================================================================================\n",
      "End Time | ç»“æŸæ—¶é—´: 2025-11-04 12:21:51\n",
      "Total Duration | æ€»è€—æ—¶: 1308.41s (21.81 minutes)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š EVALUATION SUMMARY | è¯„ä¼°æ€»ç»“\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ˆ Overall Statistics | æ€»ä½“ç»Ÿè®¡:\n",
      "  Total Episodes | æ€»å›åˆæ•°:        100\n",
      "  Successful | æˆåŠŸ:               98\n",
      "  Failed | å¤±è´¥:                   2\n",
      "  Timeout | è¶…æ—¶:                  2\n",
      "  Success Rate | æˆåŠŸç‡:           98.00%\n",
      "\n",
      "â±ï¸  Time Statistics | æ—¶é—´ç»Ÿè®¡:\n",
      "  Average Duration | å¹³å‡è€—æ—¶:    13.04s\n",
      "  Min Duration | æœ€çŸ­è€—æ—¶:        8.98s\n",
      "  Max Duration | æœ€é•¿è€—æ—¶:        30.27s\n",
      "\n",
      "ğŸ¯ Step Statistics | æ­¥æ•°ç»Ÿè®¡:\n",
      "  Average Steps | å¹³å‡æ­¥æ•°:       133.7\n",
      "  Min Steps | æœ€å°‘æ­¥æ•°:           94\n",
      "  Max Steps | æœ€å¤šæ­¥æ•°:           316\n",
      "\n",
      "âœ… Success Statistics | æˆåŠŸå›åˆç»Ÿè®¡:\n",
      "  Avg Steps (Success) | æˆåŠŸå¹³å‡æ­¥æ•°: 130.1\n",
      "  Min Steps (Success) | æˆåŠŸæœ€å°‘æ­¥æ•°: 94\n",
      "  Max Steps (Success) | æˆåŠŸæœ€å¤šæ­¥æ•°: 195\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Results saved to: evaluation_results_20251104_120003.txt | ç»“æœå·²ä¿å­˜åˆ°: evaluation_results_20251104_120003.txt\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# SmolVLA Policy Evaluation with Timeout and Success Rate Statistics\n",
    "# SmolVLAç­–ç•¥è¯„ä¼°è„šæœ¬ï¼ˆå¸¦è¶…æ—¶æœºåˆ¶å’ŒæˆåŠŸç‡ç»Ÿè®¡ï¼‰\n",
    "# ========================================================================\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# ========================================================================\n",
    "# Configuration | é…ç½®å‚æ•°\n",
    "# ========================================================================\n",
    "\n",
    "NUM_EPISODES = 100        # Total number of episodes to test | æµ‹è¯•å›åˆæ€»æ•°\n",
    "TIMEOUT_SECONDS = 30      # Timeout for each episode (seconds) | æ¯å›åˆè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "CONTROL_FREQUENCY = 20    # Control frequency (Hz) | æ§åˆ¶é¢‘ç‡ï¼ˆèµ«å…¹ï¼‰\n",
    "MAX_STEPS_PER_EPISODE = TIMEOUT_SECONDS * CONTROL_FREQUENCY  # æœ€å¤§æ­¥æ•° = 30ç§’ Ã— 20Hz = 600æ­¥\n",
    "\n",
    "# ========================================================================\n",
    "# Statistics Container | ç»Ÿè®¡æ•°æ®å®¹å™¨\n",
    "# ========================================================================\n",
    "\n",
    "class EvaluationStats:\n",
    "    \"\"\"\n",
    "    Container for evaluation statistics\n",
    "    è¯„ä¼°ç»Ÿè®¡æ•°æ®å®¹å™¨\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.total_episodes = 0          # æ€»å›åˆæ•°\n",
    "        self.successful_episodes = 0     # æˆåŠŸå›åˆæ•°\n",
    "        self.failed_episodes = 0         # å¤±è´¥å›åˆæ•°\n",
    "        self.timeout_episodes = 0        # è¶…æ—¶å›åˆæ•°\n",
    "        self.episode_durations = []      # æ¯å›åˆè€—æ—¶åˆ—è¡¨\n",
    "        self.episode_steps = []          # æ¯å›åˆæ­¥æ•°åˆ—è¡¨\n",
    "        self.success_steps = []          # æˆåŠŸå›åˆçš„æ­¥æ•°\n",
    "        \n",
    "    def add_episode(self, success, timeout, duration, steps):\n",
    "        \"\"\"\n",
    "        Add episode result to statistics\n",
    "        æ·»åŠ å›åˆç»“æœåˆ°ç»Ÿè®¡æ•°æ®\n",
    "        \n",
    "        Args:\n",
    "            success: Whether the episode succeeded | æ˜¯å¦æˆåŠŸ\n",
    "            timeout: Whether the episode timed out | æ˜¯å¦è¶…æ—¶\n",
    "            duration: Episode duration in seconds | å›åˆè€—æ—¶ï¼ˆç§’ï¼‰\n",
    "            steps: Number of steps taken | æ‰§è¡Œçš„æ­¥æ•°\n",
    "        \"\"\"\n",
    "        self.total_episodes += 1\n",
    "        self.episode_durations.append(duration)\n",
    "        self.episode_steps.append(steps)\n",
    "        \n",
    "        if success:\n",
    "            self.successful_episodes += 1\n",
    "            self.success_steps.append(steps)\n",
    "        elif timeout:\n",
    "            self.timeout_episodes += 1\n",
    "            self.failed_episodes += 1\n",
    "        else:\n",
    "            self.failed_episodes += 1\n",
    "    \n",
    "    def get_success_rate(self):\n",
    "        \"\"\"Calculate success rate | è®¡ç®—æˆåŠŸç‡\"\"\"\n",
    "        if self.total_episodes == 0:\n",
    "            return 0.0\n",
    "        return (self.successful_episodes / self.total_episodes) * 100\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"\n",
    "        Print evaluation summary\n",
    "        æ‰“å°è¯„ä¼°æ€»ç»“\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ğŸ“Š EVALUATION SUMMARY | è¯„ä¼°æ€»ç»“\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ Overall Statistics | æ€»ä½“ç»Ÿè®¡:\")\n",
    "        print(f\"  Total Episodes | æ€»å›åˆæ•°:        {self.total_episodes}\")\n",
    "        print(f\"  Successful | æˆåŠŸ:               {self.successful_episodes}\")\n",
    "        print(f\"  Failed | å¤±è´¥:                   {self.failed_episodes}\")\n",
    "        print(f\"  Timeout | è¶…æ—¶:                  {self.timeout_episodes}\")\n",
    "        print(f\"  Success Rate | æˆåŠŸç‡:           {self.get_success_rate():.2f}%\")\n",
    "        \n",
    "        if self.episode_durations:\n",
    "            print(f\"\\nâ±ï¸  Time Statistics | æ—¶é—´ç»Ÿè®¡:\")\n",
    "            print(f\"  Average Duration | å¹³å‡è€—æ—¶:    {np.mean(self.episode_durations):.2f}s\")\n",
    "            print(f\"  Min Duration | æœ€çŸ­è€—æ—¶:        {np.min(self.episode_durations):.2f}s\")\n",
    "            print(f\"  Max Duration | æœ€é•¿è€—æ—¶:        {np.max(self.episode_durations):.2f}s\")\n",
    "        \n",
    "        if self.episode_steps:\n",
    "            print(f\"\\nğŸ¯ Step Statistics | æ­¥æ•°ç»Ÿè®¡:\")\n",
    "            print(f\"  Average Steps | å¹³å‡æ­¥æ•°:       {np.mean(self.episode_steps):.1f}\")\n",
    "            print(f\"  Min Steps | æœ€å°‘æ­¥æ•°:           {np.min(self.episode_steps)}\")\n",
    "            print(f\"  Max Steps | æœ€å¤šæ­¥æ•°:           {np.max(self.episode_steps)}\")\n",
    "        \n",
    "        if self.success_steps:\n",
    "            print(f\"\\nâœ… Success Statistics | æˆåŠŸå›åˆç»Ÿè®¡:\")\n",
    "            print(f\"  Avg Steps (Success) | æˆåŠŸå¹³å‡æ­¥æ•°: {np.mean(self.success_steps):.1f}\")\n",
    "            print(f\"  Min Steps (Success) | æˆåŠŸæœ€å°‘æ­¥æ•°: {np.min(self.success_steps)}\")\n",
    "            print(f\"  Max Steps (Success) | æˆåŠŸæœ€å¤šæ­¥æ•°: {np.max(self.success_steps)}\")\n",
    "        \n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ========================================================================\n",
    "# Main Evaluation Loop | ä¸»è¯„ä¼°å¾ªç¯\n",
    "# ========================================================================\n",
    "\n",
    "def evaluate_policy_with_timeout():\n",
    "    \"\"\"\n",
    "    Evaluate policy performance with timeout mechanism\n",
    "    è¯„ä¼°ç­–ç•¥æ€§èƒ½ï¼ˆå¸¦è¶…æ—¶æœºåˆ¶ï¼‰\n",
    "    \"\"\"\n",
    "    # åˆå§‹åŒ–ç»Ÿè®¡å¯¹è±¡ Initialize statistics object\n",
    "    stats = EvaluationStats()\n",
    "    \n",
    "    # è®°å½•å¼€å§‹æ—¶é—´ Record start time\n",
    "    evaluation_start_time = datetime.now()\n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸš€ STARTING POLICY EVALUATION | å¼€å§‹ç­–ç•¥è¯„ä¼°\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Start Time | å¼€å§‹æ—¶é—´: {evaluation_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Total Episodes | æ€»å›åˆæ•°: {NUM_EPISODES}\")\n",
    "    print(f\"Timeout | è¶…æ—¶æ—¶é—´: {TIMEOUT_SECONDS}s\")\n",
    "    print(f\"Control Frequency | æ§åˆ¶é¢‘ç‡: {CONTROL_FREQUENCY}Hz\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Episode Loop | å›åˆå¾ªç¯\n",
    "    # ====================================================================\n",
    "    for episode_idx in range(NUM_EPISODES):\n",
    "        # é‡ç½®ç¯å¢ƒå’Œç­–ç•¥ Reset environment and policy\n",
    "        PnPEnv.reset(seed=episode_idx)  # ä½¿ç”¨ä¸åŒçš„seedç¡®ä¿å¤šæ ·æ€§ Use different seed for diversity\n",
    "        policy.reset()\n",
    "        policy.eval()\n",
    "        \n",
    "        # åˆå§‹åŒ–å›åˆå˜é‡ Initialize episode variables\n",
    "        step = 0                           # å½“å‰æ­¥æ•°è®¡æ•°å™¨ Current step counter\n",
    "        episode_start_time = time.time()   # å›åˆå¼€å§‹æ—¶é—´ Episode start time\n",
    "        episode_success = False            # æˆåŠŸæ ‡å¿— Success flag\n",
    "        episode_timeout = False            # è¶…æ—¶æ ‡å¿— Timeout flag\n",
    "        \n",
    "        print(f\"Episode {episode_idx + 1}/{NUM_EPISODES} started... | å›åˆ {episode_idx + 1}/{NUM_EPISODES} å¼€å§‹...\", end=\" \")\n",
    "        \n",
    "        # ================================================================\n",
    "        # Step Loop | æ­¥éª¤å¾ªç¯\n",
    "        # ================================================================\n",
    "        while PnPEnv.env.is_viewer_alive():\n",
    "            # æ¨è¿›ç‰©ç†ä»¿çœŸ Advance physics simulation\n",
    "            PnPEnv.step_env()\n",
    "            \n",
    "            # æŒ‰æ§åˆ¶é¢‘ç‡æ‰§è¡Œï¼ˆ20Hz = æ¯ç§’20æ¬¡ï¼‰\n",
    "            # Execute at control frequency (20Hz = 20 times per second)\n",
    "            if PnPEnv.env.loop_every(HZ=CONTROL_FREQUENCY):\n",
    "                \n",
    "                # ========================================================\n",
    "                # Timeout Check | è¶…æ—¶æ£€æŸ¥\n",
    "                # ========================================================\n",
    "                current_time = time.time()\n",
    "                elapsed_time = current_time - episode_start_time\n",
    "                \n",
    "                if elapsed_time > TIMEOUT_SECONDS:\n",
    "                    episode_timeout = True\n",
    "                    print(f\"â±ï¸  TIMEOUT after {elapsed_time:.1f}s | è¶…æ—¶\")\n",
    "                    break\n",
    "                \n",
    "                # ========================================================\n",
    "                # Success Check | æˆåŠŸæ£€æŸ¥\n",
    "                # ========================================================\n",
    "                success = PnPEnv.check_success()\n",
    "                if success:\n",
    "                    episode_success = True\n",
    "                    episode_duration = time.time() - episode_start_time\n",
    "                    print(f\"âœ… SUCCESS in {episode_duration:.2f}s ({step} steps) | æˆåŠŸ\")\n",
    "                    break\n",
    "                \n",
    "                # ========================================================\n",
    "                # State Observation | çŠ¶æ€è§‚æµ‹\n",
    "                # ========================================================\n",
    "                # è·å–æœºå™¨äººå…³èŠ‚çŠ¶æ€ï¼ˆå‰6ä¸ªå…³èŠ‚ï¼‰\n",
    "                # Get robot joint states (first 6 joints)\n",
    "                state = PnPEnv.get_joint_state()[:6]\n",
    "                \n",
    "                # ========================================================\n",
    "                # Image Observation | å›¾åƒè§‚æµ‹\n",
    "                # ========================================================\n",
    "                # è·å–ä¸¤ä¸ªæ‘„åƒå¤´çš„å›¾åƒï¼šç¬¬ä¸‰äººç§°è§†è§’ + è…•éƒ¨è§†è§’\n",
    "                # Get images from two cameras: third-person view + wrist view\n",
    "                image, wrist_image = PnPEnv.grab_image()\n",
    "                \n",
    "                # å›¾åƒé¢„å¤„ç†ï¼šPILæ ¼å¼ -> è°ƒæ•´å¤§å° -> Tensor\n",
    "                # Image preprocessing: PIL format -> Resize -> Tensor\n",
    "                image = Image.fromarray(image)           # NumPyæ•°ç»„è½¬PILå›¾åƒ NumPy array to PIL image\n",
    "                image = image.resize((256, 256))         # è°ƒæ•´åˆ°256x256 Resize to 256x256\n",
    "                image = IMG_TRANSFORM(image)             # è½¬ä¸ºTensor [0,1] Convert to Tensor [0,1]\n",
    "                \n",
    "                wrist_image = Image.fromarray(wrist_image)\n",
    "                wrist_image = wrist_image.resize((256, 256))\n",
    "                wrist_image = IMG_TRANSFORM(wrist_image)\n",
    "                \n",
    "                # ========================================================\n",
    "                # Prepare Model Input | å‡†å¤‡æ¨¡å‹è¾“å…¥\n",
    "                # ========================================================\n",
    "                data = {\n",
    "                    # å…³èŠ‚çŠ¶æ€ï¼š[1, 6] å¼ é‡ Joint state: [1, 6] tensor\n",
    "                    'observation.state': torch.tensor([state]).to(device),\n",
    "                    \n",
    "                    # ç¬¬ä¸‰äººç§°å›¾åƒï¼š[1, 3, 256, 256] å¼ é‡ Third-person image: [1, 3, 256, 256] tensor\n",
    "                    'observation.image': image.unsqueeze(0).to(device),\n",
    "                    \n",
    "                    # è…•éƒ¨å›¾åƒï¼š[1, 3, 256, 256] å¼ é‡ Wrist image: [1, 3, 256, 256] tensor\n",
    "                    'observation.wrist_image': wrist_image.unsqueeze(0).to(device),\n",
    "                    \n",
    "                    # ä»»åŠ¡æè¿°ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰Task description (natural language)\n",
    "                    'task': [PnPEnv.instruction],  # ä¾‹å¦‚ï¼š\"pick the mug\" or \"place the plate\"\n",
    "                }\n",
    "                \n",
    "                # ========================================================\n",
    "                # Policy Inference | ç­–ç•¥æ¨ç†\n",
    "                # ========================================================\n",
    "                # æ¨¡å‹é¢„æµ‹åŠ¨ä½œï¼ˆæ— æ¢¯åº¦è®¡ç®—ï¼‰\n",
    "                # Model predicts action (no gradient computation)\n",
    "                with torch.no_grad():\n",
    "                    action = policy.select_action(data)  # è¾“å‡ºshape: [1, chunk_size, 7]\n",
    "                    action = action[0, :7].cpu().numpy() # å–ç¬¬ä¸€æ­¥åŠ¨ä½œ: [7]\n",
    "                \n",
    "                # åŠ¨ä½œç»´åº¦è¯´æ˜ Action dimensions:\n",
    "                # action[0:6] - 6ä¸ªå…³èŠ‚çš„ç›®æ ‡è§’åº¦æˆ–è§’åº¦å¢é‡ 6 joint angles or increments\n",
    "                # action[6]   - å¤¹çˆªå¼€åˆçŠ¶æ€ Gripper open/close state\n",
    "                \n",
    "                # ========================================================\n",
    "                # Execute Action | æ‰§è¡ŒåŠ¨ä½œ\n",
    "                # ========================================================\n",
    "                _ = PnPEnv.step(action)\n",
    "                \n",
    "                # ========================================================\n",
    "                # Render Visualization | æ¸²æŸ“å¯è§†åŒ–\n",
    "                # ========================================================\n",
    "                PnPEnv.render()\n",
    "                \n",
    "                # æ­¥æ•°é€’å¢ Increment step counter\n",
    "                step += 1\n",
    "                \n",
    "                # æ­¥æ•°é™åˆ¶æ£€æŸ¥ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰\n",
    "                # Step limit check (prevent infinite loop)\n",
    "                if step >= MAX_STEPS_PER_EPISODE:\n",
    "                    episode_timeout = True\n",
    "                    print(f\"â±ï¸  MAX STEPS REACHED | è¾¾åˆ°æœ€å¤§æ­¥æ•°\")\n",
    "                    break\n",
    "        \n",
    "        # ================================================================\n",
    "        # Episode End | å›åˆç»“æŸ\n",
    "        # ================================================================\n",
    "        episode_duration = time.time() - episode_start_time\n",
    "        \n",
    "        # è®°å½•ç»Ÿè®¡æ•°æ® Record statistics\n",
    "        stats.add_episode(\n",
    "            success=episode_success,\n",
    "            timeout=episode_timeout,\n",
    "            duration=episode_duration,\n",
    "            steps=step\n",
    "        )\n",
    "        \n",
    "        # æ¯10å›åˆæ‰“å°è¿›åº¦ Print progress every 10 episodes\n",
    "        if (episode_idx + 1) % 10 == 0:\n",
    "            current_success_rate = stats.get_success_rate()\n",
    "            print(f\"\\nğŸ“Š Progress: {episode_idx + 1}/{NUM_EPISODES} | \"\n",
    "                  f\"Success Rate: {current_success_rate:.2f}% | \"\n",
    "                  f\"æˆåŠŸç‡: {current_success_rate:.2f}%\\n\")\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Evaluation Complete | è¯„ä¼°å®Œæˆ\n",
    "    # ====================================================================\n",
    "    evaluation_end_time = datetime.now()\n",
    "    total_duration = (evaluation_end_time - evaluation_start_time).total_seconds()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ‰ EVALUATION COMPLETED | è¯„ä¼°å®Œæˆ\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"End Time | ç»“æŸæ—¶é—´: {evaluation_end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Total Duration | æ€»è€—æ—¶: {total_duration:.2f}s ({total_duration/60:.2f} minutes)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # æ‰“å°è¯¦ç»†ç»Ÿè®¡ Print detailed statistics\n",
    "    stats.print_summary()\n",
    "    \n",
    "    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ Save results to file\n",
    "    save_evaluation_results(stats, evaluation_start_time, evaluation_end_time)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# ========================================================================\n",
    "# Save Results to File | ä¿å­˜ç»“æœåˆ°æ–‡ä»¶\n",
    "# ========================================================================\n",
    "\n",
    "def save_evaluation_results(stats, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Save evaluation results to a text file\n",
    "    ä¿å­˜è¯„ä¼°ç»“æœåˆ°æ–‡æœ¬æ–‡ä»¶\n",
    "    \"\"\"\n",
    "    timestamp = start_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"evaluation_results_{timestamp}.txt\"\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"SmolVLA Policy Evaluation Results\\n\")\n",
    "        f.write(\"SmolVLAç­–ç•¥è¯„ä¼°ç»“æœ\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Start Time | å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"End Time | ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Duration | æ€»è€—æ—¶: {(end_time - start_time).total_seconds():.2f}s\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Total Episodes | æ€»å›åˆæ•°: {stats.total_episodes}\\n\")\n",
    "        f.write(f\"Successful | æˆåŠŸ: {stats.successful_episodes}\\n\")\n",
    "        f.write(f\"Failed | å¤±è´¥: {stats.failed_episodes}\\n\")\n",
    "        f.write(f\"Timeout | è¶…æ—¶: {stats.timeout_episodes}\\n\")\n",
    "        f.write(f\"Success Rate | æˆåŠŸç‡: {stats.get_success_rate():.2f}%\\n\\n\")\n",
    "        \n",
    "        if stats.episode_durations:\n",
    "            f.write(f\"Average Duration | å¹³å‡è€—æ—¶: {np.mean(stats.episode_durations):.2f}s\\n\")\n",
    "            f.write(f\"Average Steps | å¹³å‡æ­¥æ•°: {np.mean(stats.episode_steps):.1f}\\n\")\n",
    "        \n",
    "        if stats.success_steps:\n",
    "            f.write(f\"Average Steps (Success) | æˆåŠŸå¹³å‡æ­¥æ•°: {np.mean(stats.success_steps):.1f}\\n\")\n",
    "    \n",
    "    print(f\"ğŸ“ Results saved to: {filename} | ç»“æœå·²ä¿å­˜åˆ°: {filename}\")\n",
    "\n",
    "# ========================================================================\n",
    "# Execute Evaluation | æ‰§è¡Œè¯„ä¼°\n",
    "# ========================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # è¿è¡Œè¯„ä¼° Run evaluation\n",
    "    evaluation_stats = evaluate_policy_with_timeout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a7d54a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2603290/3859105902.py:30: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  'observation.state': torch.tensor([state]).to(device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n",
      "Success\n",
      "DONE INITIALIZATION\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 36\u001b[0m\n\u001b[1;32m     29\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservation.state\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor([state])\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservation.image\u001b[39m\u001b[38;5;124m'\u001b[39m: image\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservation.wrist_image\u001b[39m\u001b[38;5;124m'\u001b[39m: wrist_image\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m: [PnPEnv\u001b[38;5;241m.\u001b[39minstruction],\n\u001b[1;32m     34\u001b[0m }\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Select an action\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m action \u001b[38;5;241m=\u001b[39m action[\u001b[38;5;241m0\u001b[39m,:\u001b[38;5;241m7\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Take a step in the environment\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/policies/smolvla/modeling_smolvla.py:296\u001b[0m, in \u001b[0;36mSmolVLAPolicy.select_action\u001b[0;34m(self, batch, noise)\u001b[0m\n\u001b[1;32m    293\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_state(batch)\n\u001b[1;32m    294\u001b[0m lang_tokens, lang_masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_language(batch)\n\u001b[0;32m--> 296\u001b[0m actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_actions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Unpad actions\u001b[39;00m\n\u001b[1;32m    300\u001b[0m original_action_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39maction_feature\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/policies/smolvla/modeling_smolvla.py:757\u001b[0m, in \u001b[0;36mVLAFlowMatching.sample_actions\u001b[0;34m(self, images, img_masks, lang_tokens, lang_masks, state, noise)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m time \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mdt \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    756\u001b[0m     expanded_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mexpand(bsize)\n\u001b[0;32m--> 757\u001b[0m     v_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenoise_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix_pad_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpanded_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;66;03m# Euler step\u001b[39;00m\n\u001b[1;32m    764\u001b[0m     x_t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dt \u001b[38;5;241m*\u001b[39m v_t\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/policies/smolvla/modeling_smolvla.py:776\u001b[0m, in \u001b[0;36mVLAFlowMatching.denoise_step\u001b[0;34m(self, prefix_pad_masks, past_key_values, x_t, timestep)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdenoise_step\u001b[39m(\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    770\u001b[0m     prefix_pad_masks,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    773\u001b[0m     timestep,\n\u001b[1;32m    774\u001b[0m ):\n\u001b[1;32m    775\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply one denoising step of the noise `x_t` at a given timestep.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 776\u001b[0m     suffix_embs, suffix_pad_masks, suffix_att_masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_suffix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m     suffix_len \u001b[38;5;241m=\u001b[39m suffix_pad_masks\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    779\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m prefix_pad_masks\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/envs/lerobot-mujoco/lib/python3.10/site-packages/lerobot/common/policies/smolvla/modeling_smolvla.py:685\u001b[0m, in \u001b[0;36mVLAFlowMatching.embed_suffix\u001b[0;34m(self, noisy_actions, timestep)\u001b[0m\n\u001b[1;32m    683\u001b[0m embs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(embs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    684\u001b[0m pad_masks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(pad_masks, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 685\u001b[0m att_masks \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43matt_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m att_masks \u001b[38;5;241m=\u001b[39m att_masks[\u001b[38;5;28;01mNone\u001b[39;00m, :]\u001b[38;5;241m.\u001b[39mexpand(bsize, \u001b[38;5;28mlen\u001b[39m(att_masks))\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embs, pad_masks, att_masks\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "PnPEnv.reset(seed=0)\n",
    "policy.reset()\n",
    "policy.eval()\n",
    "save_image = True\n",
    "IMG_TRANSFORM = get_default_transform()\n",
    "while PnPEnv.env.is_viewer_alive():\n",
    "    PnPEnv.step_env()\n",
    "    if PnPEnv.env.loop_every(HZ=20):\n",
    "        # Check if the task is completed\n",
    "        success = PnPEnv.check_success()\n",
    "        if success:\n",
    "            print('Success')\n",
    "            # Reset the environment and action queue\n",
    "            policy.reset()\n",
    "            PnPEnv.reset()\n",
    "            step = 0\n",
    "            save_image = False\n",
    "        # Get the current state of the environment\n",
    "        state = PnPEnv.get_joint_state()[:6]\n",
    "        # Get the current image from the environment\n",
    "        image, wirst_image = PnPEnv.grab_image()\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((256, 256))\n",
    "        image = IMG_TRANSFORM(image)\n",
    "        wrist_image = Image.fromarray(wirst_image)\n",
    "        wrist_image = wrist_image.resize((256, 256))\n",
    "        wrist_image = IMG_TRANSFORM(wrist_image)\n",
    "        data = {\n",
    "            'observation.state': torch.tensor([state]).to(device),\n",
    "            'observation.image': image.unsqueeze(0).to(device),\n",
    "            'observation.wrist_image': wrist_image.unsqueeze(0).to(device),\n",
    "            'task': [PnPEnv.instruction],\n",
    "        }\n",
    "        # Select an action\n",
    "        action = policy.select_action(data)\n",
    "        action = action[0,:7].cpu().detach().numpy()\n",
    "        # Take a step in the environment\n",
    "        _ = PnPEnv.step(action)\n",
    "        PnPEnv.render()\n",
    "        step += 1\n",
    "        success = PnPEnv.check_success()\n",
    "        if success:\n",
    "            print('Success')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b593df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy.push_to_hub(\n",
    "#     repo_id='Jeongeun/omy_pnp_smolvla',\n",
    "#     commit_message='Add trained policy for PnP task',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cb9032",
   "metadata": {},
   "outputs": [],
   "source": [
    "PnPEnv.env.close_viewer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot-mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
